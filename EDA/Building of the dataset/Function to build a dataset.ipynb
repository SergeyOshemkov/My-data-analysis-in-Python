{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-deputy",
   "metadata": {},
   "source": [
    "#### Функция для сборки финального датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаю библиотеки:\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-morgan",
   "metadata": {},
   "source": [
    "Предполагая что сбор данных из таких датасетов может представлять собой регулярную \n",
    "процедуру - решил сделать сборку данных в Питоне. На вход функции необходимо подать \n",
    "путь до папки с датасетами. На выходе получаю собранный датафрейм, который дальше загружаю в Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "monetary-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFunction(path):\n",
    "\n",
    "    # Сохраняю в список названия файлов для формирования пути к датасетам:\n",
    "    file_names = os.listdir(path)\n",
    "\n",
    "    # Формирую заголовок и убираю лишние колонки из датафрейма:\n",
    "    header = (pd.read_csv(f'{path}/{file_names[0]}', \n",
    "                            header=None,\n",
    "                            skiprows = 4,       \n",
    "                            sep=';', \n",
    "                            encoding='windows-1251')[:1]).iloc[:,:14]\n",
    "\n",
    "    # Название 13го столбца находится в исходном файле на строчку ниже:\n",
    "    header[13] = (pd.read_csv(f'{path}/{file_names[0]}', \n",
    "                  header=None,\n",
    "                  skiprows = 5,       \n",
    "                  sep=';', \n",
    "                  encoding='windows-1251')[:1]).iloc[:,13]\n",
    "\n",
    "    # Создаю пустой датарейм для объединения датасетов:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # В цикле последовательно получаю путь к каждому из датасетов:\n",
    "    for file_name in file_names:\n",
    "        data_path = f'{path}/{file_name}'\n",
    "\n",
    "    # Загружаю один за другим датафреймы для объединения:\n",
    "        temp_df = (pd.read_csv(data_path, \n",
    "                              header=None,\n",
    "                              skiprows = 7,       \n",
    "                              sep=';', \n",
    "                              encoding='windows-1251')).iloc[:,:14]\n",
    "\n",
    "    # Добавляю данные о дате отчета и дате выгрузки:    \n",
    "        temp_df['Дата отчета'] = data_path.split('_')[3][-10:]\n",
    "        temp_df['Дата выгрузки'] = data_path.split('_')[5][:-4]\n",
    "            \n",
    "    # Объединяю датафреймы:\n",
    "        df = pd.concat([df, temp_df])\n",
    "    \n",
    "    # Переименовываю колонки в финальном датафрейме:\n",
    "    header = list(header.transpose()[0].to_list())\n",
    "    header.append('Дата отчета')\n",
    "    header.append('Дата выгрузки')\n",
    "    df.columns = header\n",
    "\n",
    "    # Записываю объединенный датасет в файл:\n",
    "    print(f'Job is done! Use the link: {path} to find your complete dataframe  and have a nice day!')\n",
    "    return df.to_csv('./final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-offering",
   "metadata": {},
   "source": [
    "#### Запуск функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "strong-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job is done! Use the link: ./datasets/IBI/test_task to find your complete dataframe  and have a nice day!\n"
     ]
    }
   ],
   "source": [
    "# Файлы хранятся по ссылке:\n",
    "path = './datasets/IBI/test_task'\n",
    "\n",
    "DataFunction(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-antenna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяю размер получившегося датафрейма:\n",
    "\n",
    "print(df.shape)\n",
    "# (258611, 16)\n",
    "\n",
    "# Проверяю на дубликаты:\n",
    "df.duplicated().sum()\n",
    "# 0\n",
    "\n",
    "# Проверяю на количество пропущенных значений:\n",
    "df.isna().sum()\n",
    "\n",
    "Головное подразделение            3133\n",
    "Guid головное подразделение       3144\n",
    "Назначение использования ТМЦ     11185\n",
    "Guid_Назначение использования    11185\n",
    "Склад                              517\n",
    "Guid_Склад                         517\n",
    "Наименование участка               583\n",
    "Guid Наименование участка          583\n",
    "Номенклатура                        11\n",
    "Guid_Номенклатура                   19\n",
    "Дата последнего движения            16\n",
    "Срок хранения                    13278\n",
    "Остаток                              2\n",
    "Сумма                            98717\n",
    "Дата отчета                          0\n",
    "Дата выгрузки                        0\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-framing",
   "metadata": {},
   "source": [
    "Здесь, возможно, пригодится добавить автоматическое формирование summary с количеством пропущенных значений по столбцам, количеством и составом дубликатов и автоматическую проверку на то, имена всех ли файлов соответствуют стандарту и удалось ли обработать все датасеты. И затем также выгружать summary в файл отчета о работе функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "Код на Гитхабе: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-sunset",
   "metadata": {},
   "source": [
    "####                                                                                  Спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
